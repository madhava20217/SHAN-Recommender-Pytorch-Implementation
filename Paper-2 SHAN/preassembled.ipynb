{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import torch\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import srdatasets\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device =torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "srdatasets process --dataset=Amazon-VideoGames --split-by=user --task=long-short --target-len=1 --session-interval=120 --min-freq-item=0 --min-freq-user=0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from srdatasets.dataloader_pytorch import DataLoader\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "DATASET_CODE = 'c1683435794587'\n",
    "\n",
    "\n",
    "trainloader = DataLoader(\"Amazon-VideoGames\", DATASET_CODE, batch_size=BATCH_SIZE, train=True, negatives_per_target=5, include_timestamp=True)#, num_workers=8, pin_memory=True)\n",
    "valloader = DataLoader(\"Amazon-VideoGames\", DATASET_CODE, batch_size=BATCH_SIZE, train=False, development = True, include_timestamp=True)#, num_workers=8, pin_memory=True)\n",
    "testloader = DataLoader(\"Amazon-VideoGames\", DATASET_CODE, batch_size=BATCH_SIZE, train=False, include_timestamp=True)#, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65051, 27148)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users, n_items = trainloader.num_users, trainloader.num_items\n",
    "n_users, n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHAN(nn.Module):\n",
    "    def __init__(self, embedding_dims, n_users = n_users, n_items = n_items):\n",
    "        super().__init__()\n",
    "\n",
    "        #user\n",
    "        self.user_embed = nn.Embedding(n_users, embedding_dims)\n",
    "\n",
    "        #item\n",
    "        self.item_embed = nn.Embedding(n_items, embedding_dims, 0)\n",
    "\n",
    "        #long-term layer\n",
    "        self.item_trans1 = nn.Linear(embedding_dims, embedding_dims)\n",
    "        self.act_1 = nn.ReLU()\n",
    "\n",
    "        #after taking the embeddings of the item (v), feedforward them through the item_tran1 network to get h\n",
    "        #thereafter, compute the attention weights of each item by taking the softmax activation of the dotted user.h\n",
    "        #compute u_long by taking attention_weights * v for each\n",
    "\n",
    "        #short-term layer\n",
    "        self.item_trans2 = nn.Linear(embedding_dims, embedding_dims)\n",
    "        self.act_2 = nn.ReLU()\n",
    "\n",
    "        #weighting for net user representation\n",
    "        self.beta_0 = torch.randn(1, requires_grad = True).to(device)\n",
    "    \n",
    "    def forward(self, users, pre_sessions_items, cur_session_items):\n",
    "        user_rep = self.user_embed(users)[..., None]                            # batch * emb * 1\n",
    "        \n",
    "        \n",
    "        # LONG TERM \n",
    "        long_term_item_rep = self.item_embed(pre_sessions_items)\n",
    "        activated_long_term = self.act_1(self.item_trans1(long_term_item_rep))  # batch * num * emb\n",
    "        #compute attention weights\n",
    "        attention_mat_1 = torch.bmm(activated_long_term, user_rep)              # batch * num * 1     \n",
    "        attention_weights_1 = F.softmax(attention_mat_1, dim = 1)               # batch * num * 1\n",
    "        #long term representation\n",
    "        u_long = attention_weights_1*long_term_item_rep                         # batch * num * emb\n",
    "        u_long = torch.sum(u_long, dim = 1)                                     # batch * emb\n",
    "\n",
    "        #SHORT TERM\n",
    "        short_term_item_rep = self.item_embed(cur_session_items)\n",
    "        activated_short_term = self.act_2(self.item_trans2(short_term_item_rep))\n",
    "        #compute attention weights \n",
    "        attention_mat_2 = torch.bmm(activated_short_term, user_rep)\n",
    "        attention_weights_2 = F.softmax(attention_mat_2, dim = 1)\n",
    "        #short term representation\n",
    "        u_short = attention_weights_2*short_term_item_rep\n",
    "        u_short = torch.sum(u_short, dim = 1)\n",
    "\n",
    "        #HYBRID\n",
    "        u_hybrid = self.beta_0*u_long + u_short\n",
    "\n",
    "        preference_scores = u_hybrid @ self.item_embed.weight.T # batch * emb @ (n_items x emb).T\n",
    "        \n",
    "        return preference_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(preds, target):\n",
    "    bs, nitms = preds.size()\n",
    "    idx = torch.randint(0, nitms, (bs, 1)).to(device)\n",
    "    others = preds.gather(1, idx)\n",
    "    actual = preds.gather(1, target)\n",
    "\n",
    "    loss = -F.logsigmoid(actual - others)\n",
    "    loss = torch.mean(loss)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1315/1315 [00:11<00:00, 113.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(65050), tensor(27162))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = 0\n",
    "n_items = 0\n",
    "for users, pre_sessions_items, cur_session_items, target_items, _, _, _, _ in tqdm(iter(trainloader)):\n",
    "    n_users = max(n_users, max(users))\n",
    "    n_items = max(n_items, pre_sessions_items.max())\n",
    "    n_items = max(n_items, cur_session_items.max())\n",
    "    n_items = max(n_items, target_items.max())\n",
    "n_users, n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "\n",
    "    def __init__(self, patience=5, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1315/1315 [00:18<00:00, 70.39it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 172.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.726736).  Saving model ...\n",
      "Epoch 1: Training loss: 0.7590, Validation loss: 0.7267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1315/1315 [00:18<00:00, 70.40it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 236.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (0.726736 --> 0.715203).  Saving model ...\n",
      "Epoch 2: Training loss: 0.7056, Validation loss: 0.7152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1315/1315 [00:18<00:00, 70.58it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 149.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 3: Training loss: 0.6906, Validation loss: 0.7271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1315/1315 [00:18<00:00, 71.16it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 230.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 4: Training loss: 0.6723, Validation loss: 0.7346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1315/1315 [00:18<00:00, 70.54it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 173.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 5: Training loss: 0.6518, Validation loss: 0.7405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1315/1315 [00:18<00:00, 71.22it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 175.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch 6: Training loss: 0.6302, Validation loss: 0.7708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1315/1315 [00:18<00:00, 71.17it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 182.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DIMS = 20\n",
    "\n",
    "model = SHAN(embedding_dims= DIMS, n_users = n_users +1, n_items = n_items+1).to(device)\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True, path = 'shan_ed_{}.pth'.format(DIMS))\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "NUM_EPOCHS = 25\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    net_loss = 0\n",
    "    # Train\n",
    "    for users, pre_sessions_items, cur_session_items, target_items, _, _, _, _ in tqdm(iter(trainloader)):\n",
    "        # Shape\n",
    "        #   users:                          (batch_size,)\n",
    "        #   pre_sessions_items:             (batch_size, pre_sessions * max_session_len)\n",
    "        #   cur_session_items:              (batch_size, max_session_len - target_len)\n",
    "        #   target_items:                   (batch_size, target_len)\n",
    "        #   negative_samples:               (batch_size, target_len, negatives_per_target)\n",
    "        # DataType\n",
    "        #   numpy.ndarray or torch.LongTensor\\\n",
    "        optim.zero_grad()\n",
    "        users = users.to(device)\n",
    "        pre_sessions_items = pre_sessions_items.to(device)\n",
    "        cur_session_items = cur_session_items.to(device)\n",
    "        target_items = target_items.to(device)\n",
    "\n",
    "        preferences = model(users, pre_sessions_items, cur_session_items)\n",
    "        loss = loss_fn(preferences, target_items)\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        net_loss+=loss.item()\n",
    "\n",
    "    net_loss_val = 0\n",
    "    # Val\n",
    "    for users, pre_sessions_items, cur_session_items, target_items, _, _, _ in tqdm(iter(valloader)):\n",
    "        with torch.no_grad():\n",
    "            users = users.to(device)\n",
    "            pre_sessions_items = pre_sessions_items.to(device)\n",
    "            cur_session_items = cur_session_items.to(device)\n",
    "            target_items = target_items.to(device)\n",
    "\n",
    "            preferences = model(users, pre_sessions_items, cur_session_items)\n",
    "            loss = loss_fn(preferences, target_items)\n",
    "\n",
    "            net_loss_val+=loss.item()\n",
    "    net_loss = net_loss/len(trainloader)\n",
    "    net_loss_val = net_loss_val/len(valloader)\n",
    "    early_stopping(net_loss_val, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        print('-'*60)\n",
    "        break\n",
    "\n",
    "    print(\"Epoch {}: Training loss: {:.4f}, Validation loss: {:.4f}\".format(epoch+1, net_loss, net_loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -2.7698,  1.6947,  ...,  0.5771, -2.5745,  0.0255],\n",
       "        [ 0.0000, -0.4039,  0.6148,  ...,  1.6784, -0.5766, -1.1723],\n",
       "        [ 0.0000, -0.0121,  0.0837,  ..., -0.2411, -0.0976,  0.2043],\n",
       "        ...,\n",
       "        [ 0.0000,  0.1797, -0.1234,  ...,  0.0288,  0.0837, -0.1138],\n",
       "        [ 0.0000,  0.8341,  0.9508,  ...,  0.4071, -0.4671, -0.0968],\n",
       "        [ 0.0000, -0.1023, -0.3824,  ...,  0.6696, -0.4787, -0.4024]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ...,    0, 4658, 1803],\n",
       "        [   0,    0,    0,  ...,    0,    0,    0],\n",
       "        [   0,    0,    0,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [   0,    0,    0,  ...,    0,    0,    0],\n",
       "        [   0,    0,    0,  ...,    0,    0,    0],\n",
       "        [   0,    0,    0,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_sessions_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for users, pre_sessions_items, cur_session_items, target_items, pre_sessions_item_timestamps, cur_session_item_timestamps, target_item_timestamps in valloader:\n",
    "#     pass\n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('torchnew')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aae2c75324e7fdf5ebd22146e2daffaa477f8ea149f0e685be4c317c2939a685"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
